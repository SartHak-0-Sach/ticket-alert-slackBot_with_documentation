{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../utils')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from queryHelper import prodFetch, adbFetch\n",
    "from databaseHelper import *\n",
    "from sheetHelper import *\n",
    "from datetime import timedelta\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from openpyxl import Workbook\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import fitz\n",
    "import logging\n",
    "from io import BytesIO\n",
    "from datetime import datetime as dt, timedelta\n",
    "from google.oauth2 import service_account\n",
    "from google.auth.transport.requests import Request\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"sarthak_sachdev\", password = \"Sarthak@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "print('PostgreSQL Connection Established')\n",
    "\n",
    "query1 = '''\n",
    "select (created_at + INTERVAL '330 minutes')::DATE as date, complainant_id as driverId, issue_id from tickets where deleted_at is null and source in ('Inbound', 'Whatsapp', 'driverApp', 'partnerApp', 'SOS') and complainant_type = '1' and (created_at + INTERVAL '330 minutes')::DATE >= '20241001'\n",
    "'''\n",
    "\n",
    "dfTickets = pd.read_sql(query1, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.sort_values(by = ['date'], ascending = True, inplace = True)\n",
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"sarthak_sachdev\", password = \"Sarthak@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "print('PostgreSQL Connection Established')\n",
    "\n",
    "query2 = '''\n",
    "select id as issue_id, name as issue_name, issue_category_id from issues where deleted_at is null\n",
    "'''\n",
    "\n",
    "dfIssues = pd.read_sql(query2, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(dfIssues)\n",
    "\n",
    "conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"sarthak_sachdev\", password = \"Sarthak@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "print('PostgreSQL Connection Established')\n",
    "\n",
    "query3 = '''\n",
    "select id as issue_category_id, name as category_name from issue_categories where deleted_at is null\n",
    "'''\n",
    "\n",
    "dfCategories = pd.read_sql(query3, conn)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(dfCategories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = dfTickets.merge(dfIssues, how='left', on = 'issue_id')\n",
    "\n",
    "dfTickets = dfTickets.merge(dfCategories, how = 'left', on = 'issue_category_id')\n",
    "\n",
    "dfTickets.drop(columns = ['issue_category_id', 'issue_id'], inplace= True)\n",
    "\n",
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDrivers = prodFetch(\"\"\"select id, zoneId as driverZone from drivers \"\"\")\n",
    "\n",
    "dfTickets = dfTickets.merge(dfDrivers, left_on = 'driverid', right_on = 'id', how = 'left').drop(columns = ['id'])\n",
    "\n",
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyZoneWiseTickets = dfTickets.groupby(['driverZone', 'category_name', 'date']).agg(\n",
    "    ticketCount = ('driverid', 'count')\n",
    ").reset_index()\n",
    "\n",
    "dailyZoneWiseTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyIssueWiseTickets = dfTickets.groupby(['driverZone', 'category_name', 'issue_name', 'date']).agg(\n",
    "    ticketCount = ('driverid', 'count')\n",
    ").reset_index()\n",
    "dailyIssueWiseTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyIssueWiseTickets.sample(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyIssueWiseTickets.sort_values(by = [ 'date', 'category_name', 'ticketCount'], ascending = False, inplace = True)\n",
    "\n",
    "dailyIssueWiseTickets.reset_index(drop = True, inplace = True)\n",
    "dailyIssueWiseTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dailyIssueWiseTickets.groupby(['driverZone', 'date', 'category_name'])['ticketCount'].idxmax()\n",
    "\n",
    "topIssues = dailyIssueWiseTickets.loc[idx].reset_index(drop=True)\n",
    "\n",
    "topIssues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyZoneWiseTickets['date'] = pd.to_datetime(dailyZoneWiseTickets['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = dailyZoneWiseTickets['category_name'].unique()\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zone_category(dailyZoneWiseTickets, zone, category):\n",
    "    subset = dailyZoneWiseTickets[(dailyZoneWiseTickets['driverZone'] == zone) & (dailyZoneWiseTickets['category_name'] == category)]\n",
    "    subset = subset.sort_values('date')\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(data=subset, x='date', y='ticketCount', marker='o')\n",
    "    plt.title(f'Ticket Count Over Time - Zone: {zone}, Category: {category}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ticket Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_zone_category(dailyZoneWiseTickets[dailyZoneWiseTickets['date']>'20250101'], zone='NUP01', category='Navigation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calender week,month,quarter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dailyZoneWiseTickets.copy()\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# df['week_start'] = df['date'] - pd.to_timedelta(df['date'].dt.dayofweek, unit='d')\n",
    "# df['month'] = df['date'].dt.to_period('M').dt.to_timestamp()\n",
    "# df['quarter'] = df['date'].dt.to_period('Q').dt.to_timestamp()\n",
    "\n",
    "# def add_calendar_aggregates(df, group_col, prefix):\n",
    "#     agg = df.groupby(['driverZone', 'category_name', group_col])['ticketCount'].agg(\n",
    "#         **{\n",
    "#             f'{prefix}_avg': 'mean',\n",
    "#             f'{prefix}_min': 'min',\n",
    "#             f'{prefix}_max': 'max'\n",
    "#         }\n",
    "#     ).reset_index()\n",
    "    \n",
    "#     return df.merge(agg, on=['driverZone', 'category_name', group_col], how='left')\n",
    "\n",
    "# df = add_calendar_aggregates(df, 'week_start', 'weekly')\n",
    "# df = add_calendar_aggregates(df, 'month', 'monthly')\n",
    "# df = add_calendar_aggregates(df, 'quarter', 'quarterly')\n",
    "\n",
    "# df = df.sort_values(['driverZone', 'category_name', 'date'])\n",
    "\n",
    "# # df.drop(columns=['week_start', 'month', 'quarter'], inplace=True)\n",
    "\n",
    "# df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['category_name'] == 'Swap History') & (df['driverZone'] == 'LKR01')].head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rolling week,month,quarter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dailyZoneWiseTickets.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.sort_values(['driverZone', 'category_name', 'date'])\n",
    "\n",
    "windows = [(7, 'rolling7'), (30, 'rolling30'), (90, 'rolling90')]\n",
    "\n",
    "results = []\n",
    "\n",
    "for (zone, cat), group in df.groupby(['driverZone', 'category_name']):\n",
    "    group = group.set_index('date')\n",
    "    \n",
    "    for window, prefix in windows:\n",
    "        rolled_stats = (\n",
    "            group['ticketCount']\n",
    "            .shift(1)\n",
    "            .rolling(f'{window}D', min_periods=1)\n",
    "            .agg(['mean', 'min', 'max', 'std'])\n",
    "            .rename(columns={\n",
    "                'mean': f'{prefix}_avg',\n",
    "                'min': f'{prefix}_min',\n",
    "                'max': f'{prefix}_max',\n",
    "                'std': f'{prefix}_std'\n",
    "            })\n",
    "        )\n",
    "        group = group.join(rolled_stats)\n",
    "    \n",
    "    group = group.reset_index()\n",
    "    group['driverZone'] = zone\n",
    "    group['category_name'] = cat\n",
    "    results.append(group)\n",
    "\n",
    "df_final = pd.concat(results)\n",
    "\n",
    "rolling_cols = [col for col in df_final.columns if 'rolling' in col]\n",
    "df_final[rolling_cols] = df_final[rolling_cols].bfill()\n",
    "\n",
    "df_final = df_final.sort_values(['driverZone', 'category_name', 'date'])\n",
    "\n",
    "df_final.tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weekday analysis included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dailyZoneWiseTickets.copy()\n",
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "# df = df.sort_values(['driverZone', 'category_name', 'date'])\n",
    "# df['weekday'] = df['date'].dt.weekday  \n",
    "\n",
    "# windows = [(7, 'rolling7'), (30, 'rolling30'), (90, 'rolling90')]\n",
    "# results = []\n",
    "\n",
    "# for (zone, cat), group in df.groupby(['driverZone', 'category_name']):\n",
    "#     group = group.copy()\n",
    "#     group = group.set_index('date')\n",
    "\n",
    "#     for window, prefix in windows:\n",
    "#         rolled_stats = (\n",
    "#             group['ticketCount']\n",
    "#             .rolling(f'{window}D', min_periods=1)\n",
    "#             .agg(['mean', 'min', 'max', 'std'])\n",
    "#             .rename(columns={\n",
    "#                 'mean': f'{prefix}_avg',\n",
    "#                 'min': f'{prefix}_min',\n",
    "#                 'max': f'{prefix}_max',\n",
    "#                 'std': f'{prefix}_std'\n",
    "#             })\n",
    "#         )\n",
    "#         group = group.join(rolled_stats)\n",
    "\n",
    "#     group = group.reset_index()\n",
    "#     group['driverZone'] = zone\n",
    "#     group['category_name'] = cat\n",
    "\n",
    "#     weekday_stats = []\n",
    "#     for i, row in group.iterrows():\n",
    "#         past = group[\n",
    "#             (group['weekday'] == row['weekday']) &\n",
    "#             (group['date'] < row['date'])\n",
    "#         ].tail(8)\n",
    "\n",
    "#         weekday_avg = past['ticketCount'].mean()\n",
    "#         weekday_min = past['ticketCount'].min()\n",
    "#         weekday_max = past['ticketCount'].max()\n",
    "#         weekday_std = past['ticketCount'].std()\n",
    "\n",
    "#         weekday_stats.append({\n",
    "#             'weekday_avg': weekday_avg,\n",
    "#             'weekday_min': weekday_min,\n",
    "#             'weekday_max': weekday_max,\n",
    "#             'weekday_std': weekday_std\n",
    "#         })\n",
    "\n",
    "#     weekday_df = pd.DataFrame(weekday_stats)\n",
    "#     group = pd.concat([group.reset_index(drop=True), weekday_df.reset_index(drop=True)], axis=1)\n",
    "#     results.append(group)\n",
    "\n",
    "# df_final = pd.concat(results)\n",
    "\n",
    "# rolling_cols = [col for col in df_final.columns if 'rolling' in col]\n",
    "# df_final[rolling_cols] = df_final[rolling_cols].bfill()\n",
    "\n",
    "# df_final = df_final.sort_values(['driverZone', 'category_name', 'date'])\n",
    "\n",
    "# df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# continuous ticket graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ticket_trend(\n",
    "    df, zone, category, stat_prefix='rolling7',\n",
    "    metrics_to_show=['avg', 'min', 'max'],\n",
    "    start_date=None, end_date=None\n",
    "):\n",
    "    plot_df = df[(df['driverZone'] == zone) & (df['category_name'] == category)].copy()\n",
    "\n",
    "    if start_date:\n",
    "        plot_df = plot_df[plot_df['date'] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        plot_df = plot_df[plot_df['date'] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    if plot_df.empty:\n",
    "        print(\"No data found for the given filters.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(plot_df['date'], plot_df['ticketCount'], label='Daily Tickets', marker='o')\n",
    "    \n",
    "    for i, row in plot_df.iterrows():\n",
    "        plt.annotate(f\"{row['ticketCount']}\", (row['date'], row['ticketCount']),\n",
    "                textcoords=\"offset points\", xytext=(0, 5), ha='center', fontsize=8)\n",
    "\n",
    "    colors = {'avg': 'orange', 'min': 'green', 'max': 'red'}\n",
    "    for metric in metrics_to_show:\n",
    "        col_name = f'{stat_prefix}_{metric}'\n",
    "        if col_name in plot_df.columns:\n",
    "            avg_val = plot_df[col_name].mean()\n",
    "            plt.axhline(y=avg_val, color=colors.get(metric, 'gray'),\n",
    "                        linestyle='dotted', linewidth=2,\n",
    "                        label=f'{stat_prefix.title()} {metric.title()} = {avg_val:.2f}')\n",
    "    \n",
    "    avg_col = f'{stat_prefix}_avg'\n",
    "    std_col = f'{stat_prefix}_std'\n",
    "    if avg_col in plot_df.columns and std_col in plot_df.columns:\n",
    "        upper_bound = plot_df[avg_col] + plot_df[std_col] + 2\n",
    "        plt.fill_between(plot_df['date'], 0, upper_bound, color='orange', alpha=0.1,\n",
    "                        label=f\"{stat_prefix.title()} Safe Zone (avg + std + 2)\")\n",
    "\n",
    "    plt.title(f'Ticket Trend for {category} in {zone}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ticket Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flag separated ticket graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ticket_trend_flagged(\n",
    "    df, zone, category, stat_prefix='rolling7',\n",
    "    metrics_to_show=['avg', 'min', 'max'],\n",
    "    start_date=None, end_date=None\n",
    "):\n",
    "    plot_df = df[(df['driverZone'] == zone) & (df['category_name'] == category)].copy()\n",
    "\n",
    "    if start_date:\n",
    "        plot_df = plot_df[plot_df['date'] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        plot_df = plot_df[plot_df['date'] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    if plot_df.empty:\n",
    "        print(\"No data found for the given filters.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    avg_col = f'{stat_prefix}_avg'\n",
    "    std_col = f'{stat_prefix}_std'\n",
    "    plot_df['safe_zone'] = plot_df[avg_col] + plot_df[std_col] + 2\n",
    "\n",
    "    above_mask = plot_df['ticketCount'] > plot_df['safe_zone']\n",
    "    below_mask = ~above_mask\n",
    "\n",
    "    plt.plot(plot_df.loc[below_mask, 'date'], plot_df.loc[below_mask, 'ticketCount'],\n",
    "                label='Below Safe Zone', color='blue', marker='o')\n",
    "\n",
    "    plt.plot(plot_df.loc[above_mask, 'date'], plot_df.loc[above_mask, 'ticketCount'],\n",
    "                label='Above Safe Zone', color='red', marker='o')\n",
    "\n",
    "    for i, row in plot_df.iterrows():\n",
    "        plt.annotate(f\"{row['ticketCount']}\", (row['date'], row['ticketCount']),\n",
    "                textcoords=\"offset points\", xytext=(0, 5), ha='center', fontsize=8)\n",
    "\n",
    "    colors = {'avg': 'orange', 'min': 'green', 'max': 'red'}\n",
    "    for metric in metrics_to_show:\n",
    "        col_name = f'{stat_prefix}_{metric}'\n",
    "        if col_name in plot_df.columns:\n",
    "            avg_val = plot_df[col_name].mean()\n",
    "            plt.axhline(y=avg_val, color=colors.get(metric, 'gray'),\n",
    "                        linestyle='dotted', linewidth=2,\n",
    "                        label=f'{stat_prefix.title()} {metric.title()} = {avg_val:.2f}')\n",
    "    \n",
    "    avg_col = f'{stat_prefix}_avg'\n",
    "    std_col = f'{stat_prefix}_std'\n",
    "    if avg_col in plot_df.columns and std_col in plot_df.columns:\n",
    "        upper_bound = plot_df[avg_col] + plot_df[std_col] + 2\n",
    "        plt.fill_between(plot_df['date'], 0, upper_bound, color='orange', alpha=0.1,\n",
    "                        label=f\"{stat_prefix.title()} Safe Zone (avg + std + 2)\")\n",
    "\n",
    "    plt.title(f'Ticket Trend for {category} in {zone}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Ticket Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ticket_trend(\n",
    "    df=df_final,\n",
    "    zone='MRT01',\n",
    "    category='Navigation',\n",
    "    stat_prefix='rolling90',\n",
    "    metrics_to_show=['avg', 'min', 'max'],\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-03-31'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ticket_trend_flagged(\n",
    "    df=df_final,\n",
    "    zone='MRT01',\n",
    "    category='Navigation',\n",
    "    stat_prefix='rolling90',\n",
    "    metrics_to_show=['avg', 'min', 'max'],\n",
    "    start_date='2025-01-01',\n",
    "    end_date='2025-03-31'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\n",
    "    (df_final['category_name'] == 'B2B') &\n",
    "    (df_final['driverZone'] == 'LKR01') &\n",
    "    (df_final['date'] >= '2025-03-01')\n",
    "].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['safe_zone'] = pd.concat([\n",
    "    df_final['rolling7_avg'] + df_final['rolling7_std'],\n",
    "    df_final['rolling30_avg'] + df_final['rolling30_std'],\n",
    "    df_final['rolling90_avg'] + df_final['rolling90_std']\n",
    "], axis=1).max(axis=1)\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['peekFlag'] = df_final['ticketCount'] > df_final['safe_zone']\n",
    "df_final['peekFlag'] = df_final['peekFlag'].astype(int)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['countPercentage'] = 100 * df_final['ticketCount'] / df_final['safe_zone']\n",
    "df_final['ticketCountDifference'] = df_final['ticketCount'] - df_final['safe_zone']\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_columns = [\n",
    "    'date', 'driverZone', 'category_name', 'ticketCount',\n",
    "    'safe_zone', 'peekFlag', 'countPercentage', 'ticketCountDifference'\n",
    "]\n",
    "\n",
    "avg_cols = [col for col in df_final.columns if '_avg' in col]\n",
    "max_cols = [col for col in df_final.columns if '_max' in col]\n",
    "std_cols = [col for col in df_final.columns if '_std' in col]\n",
    "min_cols = [col for col in df_final.columns if '_min' in col]\n",
    "\n",
    "final_col_order = fixed_columns + avg_cols + max_cols + std_cols + min_cols \n",
    "\n",
    "df_final = df_final[final_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = pd.Timestamp.today().normalize() - pd.Timedelta(days=1)\n",
    "\n",
    "print(df_final[(df_final['peekFlag'] == 1) & (df_final['date'] == target_date) & (df_final['ticketCountDifference']>2) & (df_final['ticketCount']>=5)].count())\n",
    "df_final[(df_final['peekFlag'] == 1) & (df_final['date'] == target_date) & (df_final['ticketCountDifference']>2) & (df_final['ticketCount']>=5)].sort_values('ticketCountDifference', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_peek = df_final[(df_final['peekFlag'] == 1) & (df_final['date'] >= '20250401') & (df_final['ticketCountDifference']>2) & (df_final['ticketCount']>=5)]\n",
    "\n",
    "df_peek = df_peek.sort_values('date')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_peek['date'], df_peek['ticketCount'], label='Ticket Count', marker='o')\n",
    "plt.plot(df_peek['date'], df_peek['safe_zone'], label='Safe Zone', linestyle='--', color='red')\n",
    "\n",
    "plt.title('Ticket Count vs Safe Zone (peekFlag = 1)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal = df_final[(df_final['peekFlag'] == 1) & (df_final['date'] == target_date) & (df_final['ticketCountDifference']>2) & (df_final['ticketCount']>=5)].sort_values('ticketCountDifference', ascending = False)\n",
    "\n",
    "dfFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topIssues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinal['date'] = pd.to_datetime(dfFinal['date'])\n",
    "topIssues['date'] = pd.to_datetime(topIssues['date'])\n",
    "\n",
    "topIssues = topIssues[topIssues['date'] == target_date]\n",
    "\n",
    "dfFinalest = dfFinal.merge(topIssues[['date', 'driverZone', 'category_name', 'issue_name']], how = 'left', on = ['date', 'driverZone', 'category_name'])\n",
    "dfFinalest.rename(columns = {'issue_name': 'topIssue'}, inplace = True)\n",
    "dfFinalest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date', 'driverZone', 'category_name', 'ticketCount', 'topIssue'] + dfFinalest.columns.tolist()[4:20]\n",
    "\n",
    "dfFinalest = dfFinalest[cols]\n",
    "dfFinalest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalest['date'] = pd.to_datetime(dfFinalest['date'])\n",
    "cols = ['safe_zone', 'countPercentage', 'ticketCountDifference', 'rolling7_avg', 'rolling7_std', 'rolling30_avg', 'rolling30_std', 'rolling90_avg', 'rolling90_std']\n",
    "dfFinalest[cols] = dfFinalest[cols].round(2)\n",
    "dfFinalest['countPercentage'] = dfFinalest['countPercentage'].round(2).astype(str) + '%'\n",
    "dfFinalest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFinalest['date'] = dfFinalest['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "dfFinalest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(\"https://docs.google.com/spreadsheets/d/1aofnudXMRZL1UtMksjCy6V31QF37AQ1KGhJdar1_7-E/edit?gid=0#gid=0\", \"raw\", dfFinalest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append(\"https://docs.google.com/spreadsheets/d/1aofnudXMRZL1UtMksjCy6V31QF37AQ1KGhJdar1_7-E/edit?gid=0#gid=0\", \"dailyTicketLogs\", dfFinalest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# slack_webhook_url = 'https://hooks.slack.com/services/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'\n",
    "\n",
    "# if not dfFinal.empty:\n",
    "#     messages = []\n",
    "\n",
    "#     for _, row in dfFinal.iterrows():\n",
    "#         message = (\n",
    "#             f\":warning: Ticket count in *{row['driverZone']}* for the category *{row['category_name']}* \"\n",
    "#             f\"has reached beyond *{row['ticketCount']}*.\"\n",
    "#         )\n",
    "#         messages.append(message)\n",
    "\n",
    "#     final_message = \"\\n\".join(messages)\n",
    "\n",
    "#     payload = {\"text\": final_message}\n",
    "#     response = requests.post(slack_webhook_url, json=payload)\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         print(\"Slack message sent successfully.\")\n",
    "#     else:\n",
    "#         print(f\"Failed to send Slack message. Status code: {response.status_code}\")\n",
    "# else:\n",
    "#     print(\"No anomalies to report.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_TOKEN = os.getenv(\"SLACK_BOT_TOKEN\", 'XXX')\n",
    "TARGET_CHANNEL_ID = 'XXX'\n",
    "\n",
    "def safe_float(value):\n",
    "    try:\n",
    "        return float(str(value).replace('%', '').replace(',', '').strip())\n",
    "    except (ValueError, TypeError):\n",
    "        logging.error(f\"Error converting value to float: {value}\")\n",
    "        return None\n",
    "\n",
    "def get_severity(row):\n",
    "    percent = safe_float(row['countPercentage'])\n",
    "    diff = safe_float(row['ticketCountDifference'])\n",
    "    base_avg = safe_float(row.get('rolling7_avg', 1))\n",
    "\n",
    "    if percent is None or diff is None or base_avg is None:\n",
    "        logging.error(f\"Error in get_severity\")\n",
    "        return \"unknown\"\n",
    "\n",
    "    base_avg = max(base_avg, 1)\n",
    "    is_low_volume = base_avg < 25\n",
    "    is_high_volume = base_avg >= 25\n",
    "\n",
    "    logging.debug(f\"Row values: diff={diff}, percent={percent}, base_avg={base_avg}\")\n",
    "\n",
    "    if is_low_volume:\n",
    "        if diff >= 20 or percent >= 200:\n",
    "            return \"high\"\n",
    "        elif diff >= 10 or percent >= 100:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "\n",
    "    if is_high_volume:\n",
    "        if diff >= 50 or percent >= 70:\n",
    "            return \"high\"\n",
    "        elif diff >= 100 or percent >= 40:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "\n",
    "    if diff >= 50 or percent >= 100:\n",
    "        return \"high\"\n",
    "    elif diff >= 25 or percent >= 50:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"low\"\n",
    "\n",
    "def format_ticket_alert(row):\n",
    "    severity = get_severity(row)\n",
    "\n",
    "    severity_emoji = {\n",
    "        \"high\": \":red_circle:\",\n",
    "        \"medium\": \":large_orange_circle:\",\n",
    "        \"low\": \":large_yellow_circle:\",\n",
    "        \"unknown\": \":white_circle\" \n",
    "    }\n",
    "    \n",
    "    severity_icon = severity_emoji.get(severity, \":green_circle:\")  \n",
    "\n",
    "    try:\n",
    "        ticket_count = safe_float(row['ticketCount'])\n",
    "        rolling90_max = safe_float(row.get('rolling90_max', 0))\n",
    "        rolling30_max = safe_float(row.get('rolling30_max', 0))\n",
    "        rolling7_max = safe_float(row.get('rolling7_max', 0))\n",
    "    except (ValueError, TypeError):\n",
    "        ticket_count = rolling90_max = rolling30_max = rolling7_max = 0\n",
    "\n",
    "    peak_note = \"\"\n",
    "    if ticket_count > rolling90_max:\n",
    "        peak_note = \":chart_with_upwards_trend: Highest in L90!\"\n",
    "    elif ticket_count > rolling30_max:\n",
    "        peak_note = \":chart_with_upwards_trend: Monthly high!\"\n",
    "    elif ticket_count > rolling7_max:\n",
    "        peak_note = \":chart_with_upwards_trend: Weekly high!\"\n",
    "\n",
    "    return (\n",
    "        f\"{peak_note}\\n\"\n",
    "        f\"{severity_icon} *{row['driverZone']}* â€” *{row['category_name']}* saw *{row['ticketCount']}* tickets \"\n",
    "        f\"(+{row['ticketCountDifference']}, +{row['countPercentage']}).\\n\"\n",
    "        f\"Top issue: *{row['topIssue']}*.\\n\\n\"\n",
    "    )\n",
    "\n",
    "def send_message_to_slack_from_df(df):\n",
    "    client = WebClient(token=BOT_TOKEN)\n",
    "\n",
    "    if df.empty:\n",
    "        logging.info(\"No anomalies to report.\")\n",
    "        return\n",
    "\n",
    "    date = df['date'].iloc[0] if 'date' in df.columns else datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    header = f\"*XXXXXXXXX---Here are the ticket spikes of {date}---XXXXXXXXXXXX*\"\n",
    "    messages = [format_ticket_alert(row) for _, row in df.iterrows()]\n",
    "    final_message = f\"{header}\\n\\n\" + \"\\n\".join(messages)\n",
    "\n",
    "    try:\n",
    "        response = client.chat_postMessage(channel=TARGET_CHANNEL_ID, text=final_message)\n",
    "        logging.info(\"Slack message sent successfully.\")\n",
    "    except SlackApiError as e:\n",
    "        logging.error(f\"Error sending message to Slack: {e.response['error']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    send_message_to_slack_from_df(dfFinalest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [scraped] older statistical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets['date'] = pd.to_datetime(dfTickets['date'])\n",
    "\n",
    "# dfTickets['week'] = dfTickets['date'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# dfTickets['month'] = dfTickets['date'].dt.month.astype(int)\n",
    "\n",
    "# dfTickets['quarter'] = dfTickets['date'].dt.quarter.astype(int)\n",
    "# dfTickets\n",
    "# dailyZoneWise = dfTickets.groupby(['complainant_zone', 'category_name', 'date', 'week', 'month', 'quarter']).agg(\n",
    "#     ticketCount = ('complainant_id', 'count')\n",
    "# ).reset_index()\n",
    "\n",
    "# dailyZoneWise\n",
    "# dailyZoneWiseTickets = dailyZoneWise[['complainant_zone', 'category_name', 'date', 'ticketCount']].copy()\n",
    "# dailyZoneWiseTickets['date'] = pd.to_datetime(dailyZoneWiseTickets['date'])\n",
    "# dailyZoneWiseTickets\n",
    "# weeklyZoneWise = dfTickets.groupby(['complainant_zone', 'category_name', 'week']).agg(\n",
    "#     weeklyCount = ('complainant_id', 'count')\n",
    "# ).reset_index()\n",
    "\n",
    "# weeklyZoneWise\n",
    "# monthlyZoneWise = dfTickets.groupby(['complainant_zone', 'category_name', 'month']).agg(\n",
    "#     monthlyCount = ('complainant_id', 'count')\n",
    "# ).reset_index()\n",
    "\n",
    "# monthlyZoneWise\n",
    "# quarterlyZoneWise = dfTickets.groupby(['complainant_zone', 'category_name', 'quarter']).agg(\n",
    "#     quarterlyCount = ('complainant_id', 'count')\n",
    "# ).reset_index()\n",
    "\n",
    "# quarterlyZoneWise\n",
    "# past3daysTickets = dfTickets[dfTickets['date'] >= (datetime.now() - timedelta(days=3))]\n",
    "# past3daysTickets\n",
    "# dailyZoneWise\n",
    "# weeklyAgg = weeklyZoneWise.groupby(['complainant_zone', 'category_name'])['weeklyCount'].agg(\n",
    "#     weekly_avg='mean'\n",
    "#     # weekly_median='median',\n",
    "#     # weekly_skewness=lambda x: skew(x, bias=False) if len(x) > 2 else np.nan\n",
    "# ).reset_index()\n",
    "\n",
    "# weeklyAgg\n",
    "# monthlyAgg = monthlyZoneWise.groupby(['complainant_zone', 'category_name'])['monthlyCount'].agg(\n",
    "#     monthly_avg='mean'\n",
    "#     # monthly_median='median',\n",
    "#     # monthly_skewness=lambda x: skew(x, bias=False) if len(x) > 2 else np.nan\n",
    "# ).reset_index()\n",
    "\n",
    "# monthlyAgg\n",
    "# quarterlyAgg = quarterlyZoneWise.groupby(['complainant_zone', 'category_name'])['quarterlyCount'].agg(\n",
    "#     quarterly_avg='mean'\n",
    "#     # quarterly_median='median',\n",
    "#     # quarterly_skewness=lambda x: skew(x, bias=False) if len(x) > 2 else np.nan\n",
    "# ).reset_index()\n",
    "\n",
    "# quarterlyAgg\n",
    "# merged = dailyZoneWise.merge(weeklyAgg, how='left', on=['complainant_zone', 'category_name']).merge(monthlyAgg, how='left', on=['complainant_zone', 'category_name']).merge(quarterlyAgg, how='left', on=['complainant_zone', 'category_name'])\n",
    "\n",
    "# merged\n",
    "# weeklyStats = weeklyZoneWise.groupby(['complainant_zone', 'category_name']).agg(mean=('weeklyCount', 'mean'), std=('weeklyCount', 'std')).reset_index()\n",
    "\n",
    "# weeklyStats\n",
    "# weeklyWithStats = weeklyZoneWise.merge(weeklyStats, on=['complainant_zone', 'category_name'])\n",
    "\n",
    "# weeklyWithStats['z_score'] = ((weeklyWithStats['weeklyCount'] - weeklyWithStats['mean']) / weeklyWithStats['std']).abs()\n",
    "\n",
    "# weeklyWithStats\n",
    "# threshold = 1.5\n",
    "# weeklyWithStats['unstable'] = weeklyWithStats['z_score'] > threshold\n",
    "\n",
    "# instability = weeklyWithStats.groupby(['complainant_zone', 'category_name']).agg(\n",
    "#         unstable_weeks=('unstable', 'sum'),\n",
    "#         total_weeks=('unstable', 'count')\n",
    "#     ).reset_index()\n",
    "\n",
    "# instability['reliability_score'] = 1 - (instability['unstable_weeks'] / instability['total_weeks'])\n",
    "\n",
    "# instability\n",
    "# final = merged.merge(instability[['complainant_zone', 'category_name', 'reliability_score']],\n",
    "#                     on=['complainant_zone', 'category_name'],\n",
    "#                     how='left')\n",
    "\n",
    "# final\n",
    "# dailyZoneWiseTickets.tail(60)\n",
    "# def safe_z_score(series, window=30):\n",
    "#     roll_mean = series.rolling(window, min_periods=7).mean()\n",
    "#     roll_std = series.rolling(window, min_periods=7).std()\n",
    "\n",
    "#     z = (series - roll_mean) / roll_std\n",
    "#     z[roll_std < 1e-3] = np.nan  \n",
    "#     return z\n",
    "# valid_combinations = (\n",
    "#     dailyZoneWiseTickets.groupby(['complainant_zone', 'category_name'])['ticketCount']\n",
    "#     .sum()\n",
    "#     .reset_index()\n",
    "#     .query('ticketCount > 30')\n",
    "# )\n",
    "\n",
    "# dailyZoneWiseTickets = dailyZoneWiseTickets.merge(valid_combinations[['complainant_zone', 'category_name']], on=['complainant_zone', 'category_name'])\n",
    "# dailyZoneWiseTickets['ticketCount_log'] = np.log1p(dailyZoneWiseTickets['ticketCount'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
