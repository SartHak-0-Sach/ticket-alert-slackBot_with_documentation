{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append('../utils')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from queryHelper import prodFetch, adbFetch\n",
    "from datetime import timedelta, datetime\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_params = {\n",
    "    'dbname': 'operations_manager_prod',\n",
    "    'user': 'XXXX',\n",
    "    'password': 'XXXXX',\n",
    "    'host': 'operation.replica.upgrid.in',\n",
    "    'port': '5432'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a query with retry mechanism\n",
    "def execute_query_with_retries(query, conn_params, retries=10, delay=2):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            # Connect to the database\n",
    "            with psycopg2.connect(**conn_params) as conn:\n",
    "                df = pd.read_sql(query, conn)\n",
    "            print(\"Query executed successfully.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            print(f\"Attempt {attempt} failed: {e}\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2  # Exponential backoff\n",
    "    raise SystemExit(\"Query failed after multiple retries. Stopping execution.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = '''with v1 as \n",
    "(\n",
    "select\n",
    "    TO_CHAR((t.created_at + INTERVAL '330 minute')::date, 'YYYY-MM') as month,\n",
    "    EXTRACT(WEEK FROM (t.created_at + INTERVAL '330 minute')::date) AS week_number,\n",
    "    (case \n",
    "        when (EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 1 and EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) <= 10) then '1-10' \n",
    "        when (EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 11 and EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) <= 20) then '11-20'\n",
    "        when EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 21 then '21+' \n",
    "    end) day_cohort,\n",
    "    to_char((t.created_at + INTERVAL '330 minute')::date, 'Day') as day,\n",
    "    (t.created_at + INTERVAL '330 minute')::date AS date,\n",
    "    t.created_at + INTERVAL '330 minute' AS created_at,\n",
    "    t.updated_at + INTERVAL '330 minute' AS updated_at,\n",
    "    TO_CHAR(t.created_at + INTERVAL '330 minutes', 'HH24') as hour,\n",
    "    t.slug ticket_id,\n",
    "    tasks.status ticket_status,\n",
    "    (case when t.complainant_type = 1 then 'driver' else 'partner' end) complainant_type,\n",
    "    t.complainant_id complainant_id,\n",
    "    ic.id category_id,\n",
    "    ic.name category_name,\n",
    "    t.issue_id issue_id,\n",
    "    i1.name issue_name,\n",
    "    concat(ic.name,' - ',i1.name) category_issue,\n",
    "    t.complainant_name complainant_name,\n",
    "    t.zone complainant_zone,\n",
    "    t.source,\n",
    "    COALESCE(t.calling_number, '') calling_number,\n",
    "    tasks.id taskId,\n",
    "    COALESCE((case when iar.assignment_rule_type like '%TeamRole%' then tatr.team else NULL end),' ') assigned_to_team,\n",
    "    COALESCE((case when iar.assignment_rule_type like '%TeamRole%' then tatr.role else NULL end ), '') assigned_to_role,\n",
    "    COALESCE(tasks.location, '') taskLocation,\n",
    "    COALESCE(x.rejectionCount,0) taskRejectionCount,\n",
    "    COALESCE(x.rejectionReasons,'') rejectionReasons,\n",
    "    COALESCE(x.rejectionRemarks,'') rejectionRemarks,\n",
    "    battery_ids,\n",
    "    split_part(battery_ids, ',', 1) AS batteryid_1,\n",
    "    split_part(battery_ids, ',', 2) AS batteryid_2,\n",
    "    charger_ids,\n",
    "    partner_id, \n",
    "    driver_id\n",
    "from tickets t\n",
    "left join issues i1 on t.issue_id = i1.id\n",
    "left join issue_categories ic on ic.id = i1.issue_category_id\n",
    "left join tasks on tasks.id = t.task_id\n",
    "left join issue_assignment_rules iar on iar.issue_id = t.issue_id\n",
    "left join tickets_assignment_rules_team_roles tatr on tatr.id = iar.assignment_rule_id\n",
    "left join (\n",
    "with v1 as \n",
    "(\n",
    "select loggable_type, loggable_id, to_value, count(id) rejectionCount, string_agg(reason, E' >> ') rejectionReasons, string_agg(remark, E' >> ') rejectionRemarks from logs\n",
    "where to_value = 'rejected'\n",
    "group by 1,2,3\n",
    ")\n",
    "select * from v1) x on x.loggable_id = t.task_id\n",
    "where t.deleted_at is null and t.created_at >= '20240701' and t.created_at < '20240801'\n",
    ")\n",
    "select * from v1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch data in 5-day intervals\n",
    "def fetch_data_in_batches(start_date, end_date, conn_params):\n",
    "    # Convert string dates to datetime objects\n",
    "    start_date = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end_date = datetime.strptime(end_date, '%Y%m%d')\n",
    "\n",
    "    # Initialize a list to store dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate in 15-day intervals\n",
    "    current_start = start_date\n",
    "    while current_start < end_date:\n",
    "        current_end = min(current_start + timedelta(days=3), end_date)\n",
    "\n",
    "        # Format the date range for the query\n",
    "        date_condition = (f\"t.created_at >= '{current_start.strftime('%Y-%m-%d')}' \"\n",
    "                          f\"and t.created_at < '{current_end.strftime('%Y-%m-%d')}'\")\n",
    "\n",
    "        # Adjust the query with the date condition\n",
    "        query = query1.replace(\"t.created_at >= '20240701' and t.created_at < '20240801'\", date_condition)\n",
    "\n",
    "        print(f\"Fetching data for range: {current_start.strftime('%Y-%m-%d')} to {current_end.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # Execute the query and append the result to the list\n",
    "        try:\n",
    "            df = execute_query_with_retries(query, conn_params)\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data for range {current_start} to {current_end}: {e}\")\n",
    "\n",
    "        # Move to the next interval\n",
    "        current_start = current_end\n",
    "\n",
    "    # Concatenate all dataframes into a single dataframe\n",
    "    final_dataframe = pd.concat(dataframes, ignore_index=True) if dataframes else pd.DataFrame()\n",
    "    time.sleep(1)\n",
    "    return final_dataframe\n",
    "\n",
    "# Define the start and end date for the batch process\n",
    "start_date = '20241001'\n",
    "end_date = '20250213'\n",
    "\n",
    "# Fetch the data in 15-day intervals\n",
    "final_dataframe = fetch_data_in_batches(start_date, end_date, conn_params)\n",
    "\n",
    "# Display the final dataframe\n",
    "print(final_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = final_dataframe.copy()\n",
    "del final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"with v1 as \n",
    "(\n",
    "select\n",
    "    t.slug ticket_id,\n",
    "    1 as escalated_flag\n",
    "from\n",
    "    logs l\n",
    "left join tickets t on t.task_id = l.loggable_id\n",
    "left join tasks on tasks.id = t.task_id\n",
    "left join issues i on i.id = t.issue_id\n",
    "left join issue_categories ic on ic.id = i.issue_category_id\n",
    "left join issue_assignment_rules iar on iar.issue_id = t.issue_id\n",
    "left join tickets_assignment_rules_relationship_managers tarm on tarm.id = iar.assignment_rule_id\n",
    "left join tickets_assignment_rules_team_roles tatr on tatr.id = iar.assignment_rule_id\n",
    "where  to_value in ('escalated') and t.deleted_at is null\n",
    ")\n",
    "select * from v1\"\"\"\n",
    "\n",
    "\n",
    "# Function to execute the query with retry mechanism\n",
    "def execute_query_with_retries(query, retries=5, delay=2):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            # Connect to the database\n",
    "            with psycopg2.connect(**conn_params) as conn:\n",
    "                dfTickets = pd.read_sql(query, conn)\n",
    "            print(\"Query executed successfully.\")\n",
    "            return dfTickets\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            print(f\"Attempt {attempt} failed: {e}\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2  # Exponential backoff\n",
    "    raise SystemExit(\"Query failed after multiple retries. Stopping execution.\")\n",
    "\n",
    "# Execute the query with retry logic\n",
    "try:\n",
    "    dfEscalation = execute_query_with_retries(query2)\n",
    "except Exception as e:\n",
    "    print(\"Final attempt failed:\", e)\n",
    "\n",
    "\n",
    "dfEscalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = dfTickets.merge(dfEscalation, on = 'ticket_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['escalated_flag'] = dfTickets['escalated_flag'].fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfEscalation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"ankit_das\", password = \"Ankit@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "# print('PostgreSQL Connection Established')\n",
    "\n",
    "# query3 = '''with v1 as \n",
    "# (\n",
    "# select l.loggable_type, l.loggable_id, l.attr, l.from_value, l.to_value, l.reason, l.remark, l.event_name, l.done_by,  l.created_at + INTERVAL '330 minute' created_at, l.updated_at + INTERVAL '330 minute' updated_at,\n",
    "# COALESCE(t.parent_id,l.loggable_id) parent_Id\n",
    "# from logs l\n",
    "# left join tasks t on l.loggable_id = t.id \n",
    "# where deleted_at is null  and (t.created_at + INTERVAL '330 minute')::date >= '20240801' and l.to_value not in ('dropped')\n",
    "# ),\n",
    "# v2 as (\n",
    "# select *, rank() over(partition by parent_id order by created_at desc) rank from v1\n",
    "# )\n",
    "# select * from v2 where rank = 1\n",
    "# '''\n",
    "\n",
    "# dfTat = pd.read_sql(query3, conn)\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat['created_at'] = pd.to_datetime(dfTat['created_at'])\n",
    "# dfTat['updated_at'] = pd.to_datetime(dfTat['updated_at'])\n",
    "# dfTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat[dfTat['taskid']== 719823]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat.rename({'parent_id':'taskid'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = dfTickets.merge(dfTat, on = 'taskid', how = 'left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUsers = prodFetch(\"\"\"select employeeId temp, (case when teams in ('[]') then role else teams end) team, roleV2 from users \n",
    "# where employeeId not like 'D%' or employeeId not like 'P%'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_dict = {'[]':'', '[':'',']':'','\"':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUsers['roleV2'] = dfUsers['roleV2'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for old_char, new_char in replace_dict.items():\n",
    "#     dfUsers['team'] = dfUsers['team'].str.replace(old_char, new_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUsers['assinged_to_team'] = dfUsers['team'] + \" - \" + dfUsers['roleV2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfUsers['team']\n",
    "# del dfUsers['roleV2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat['temp'] = dfTat['done_by'].str[:8].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat = dfTat.merge(dfUsers, on = 'temp', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTat['temp']\n",
    "# dfTat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = dfTickets.merge(dfTat, on = 'taskid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets['loggable_type']\n",
    "# del dfTickets['loggable_id']\n",
    "# del dfTickets['attr']\n",
    "# del dfTickets['from_value']\n",
    "# del dfTickets['to_value']\n",
    "# del dfTickets['reason']\n",
    "# del dfTickets['remark']\n",
    "# del dfTickets['event_name']\n",
    "# del dfTickets['rank']\n",
    "# del dfTickets['created_at_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.rename({'updated_at_y':'log_timestamp','done_by':'last_assiged_to', 'created_at_x':'created_at','updated_at_x':'updated_at', 'assinged_to_team':'last_assigned_to_team'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['created_at'] = pd.to_datetime(dfTickets['created_at'])\n",
    "dfTickets['updated_at'] = pd.to_datetime(dfTickets['updated_at'])\n",
    "# dfTickets['log_timestamp'] = pd.to_datetime(dfTickets['log_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets['tat_in_hrs'] = np.where(dfTickets['ticket_status']== \"completed\", ((dfTickets['log_timestamp'] - dfTickets['created_at']).dt.total_seconds()/3600).round(1), ((pd.Timestamp.now() - dfTickets['created_at']).dt.total_seconds()/3600).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets['tat_status'] = np.where(dfTickets['tat_in_hrs'] <= dfTickets['sla_in_hrs'], \"Within_tat\", \"Outside_tat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets[dfTickets['ticket_id']=='D240805-116967']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query3 = '''with v1 as \n",
    "(\n",
    "select t.slug ticket_id, coalesce(string_agg(rs.name, ' >> '),'No Issue Found') resolution , string_agg(rt.remark, ' >>') remark from tickets t\n",
    "left join issues i on t.issue_id = i.id\n",
    "left join (select id, parent_id, type  from tasks where type in ('Tasks::SelectResolution')) ta on t.task_id = ta.parent_id\n",
    "left join resolutions_tasks rt on rt.task_id = ta.id\n",
    "left join resolutions rs on rs.id = rt.resolution_id\n",
    "group by 1\n",
    ")\n",
    "select * from v1\n",
    "'''\n",
    "# Function to execute the query with retry mechanism\n",
    "def execute_query_with_retries(query, retries=5, delay=2):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            # Connect to the database\n",
    "            with psycopg2.connect(**conn_params) as conn:\n",
    "                dfTickets = pd.read_sql(query3, conn)\n",
    "            print(\"Query executed successfully.\")\n",
    "            return dfTickets\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            print(f\"Attempt {attempt} failed: {e}\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2  # Exponential backoff\n",
    "    raise SystemExit(\"Query failed after multiple retries. Stopping execution.\")\n",
    "\n",
    "# Execute the query with retry logic\n",
    "try:\n",
    "    dfResolutions = execute_query_with_retries(query3)\n",
    "except Exception as e:\n",
    "    print(\"Final attempt failed:\", e)\n",
    "\n",
    "dfResolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResolutions[dfResolutions['ticket_id']=='D240709-26943']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverZone = prodFetch('''select id complainant_id, zoneId complainant_zone, livedate driver_ob_date from drivers''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets =  dfTickets.merge(dfDriverZone, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets[dfTickets['ticket_id']== 'D240808-129143']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['complainant_zone'] = np.where(dfTickets['complainant_type'] == 'driver', dfTickets['complainant_zone_y'], dfTickets['complainant_zone_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfTickets['complainant_zone_x']\n",
    "del dfTickets['complainant_zone_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['created_at'] = pd.to_datetime(dfTickets['created_at'].dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "dfTickets['updated_at'] = pd.to_datetime(dfTickets['updated_at'].dt.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "dfTickets['batteryid_1'] = dfTickets['batteryid_1'].str.strip()\n",
    "dfTickets['batteryid_2'] = dfTickets['batteryid_2'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['created_at'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfResolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = dfTickets.merge(dfResolutions, on = 'ticket_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfResolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets['category_issue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = ['Meter Not Working', 'Meter Stolen','Meter Not Working - Driver not ready to pay service change','Meter Not Working - Service Charge Applied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfVehicleIssue = dfTickets[dfTickets['issue_name'].isin(temp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfVehicleIssue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfVehicleIssue.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write('https://docs.google.com/spreadsheets/d/19VdawFRRbRDneVaVvz4qS5_lxRq5BdaPZ54s9iVdxDA/edit?gid=1335881675#gid=1335881675', 'New Tickets', dfVehicleIssue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBatteries = prodFetch('''select id, manufacturerName, phase, batteryType from batteries''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBatteries.rename({'id':'batteryid_1'}, axis = 1, inplace = True)\n",
    "dfTickets = dfTickets.merge(dfBatteries, on = 'batteryid_1', how = 'left')\n",
    "dfBatteries.rename({'batteryid_1':'batteryid_2'}, axis = 1, inplace = True)\n",
    "dfTickets = dfTickets.merge(dfBatteries, on = 'batteryid_2', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBatteries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfBatteries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToRename = {'manufacturerName_x':'b1_oem', 'phase_x': 'b1_phase', 'batteryType_x': 'b1_battery_type', 'manufacturerName_y':'b2_oem', 'phase_y' : 'b2_phase', 'batteryType_y':'b2_battery_type'}\n",
    "\n",
    "dfTickets.rename(colsToRename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogs = adbFetch('''select date(date_add(createdAt, interval 330 minute)) date, date_add(createdAt, interval 330 minute) createdAt, batteryId, serialNo, occupant, changedBy from batteryLogs\n",
    "# where date(createdAt) >= 20240829 and deletedAt is null''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogsCopy = dfBatteryLogs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfBatteryLogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogsCopy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogsCopy.rename({'createdAt':'created_at','batteryId':'batteryid_1'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = dfTickets.sort_values(by = ['created_at', 'batteryid_1'])\n",
    "# dfBatteryLogsCopy = dfBatteryLogsCopy.sort_values(by = ['created_at', 'batteryid_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogsCopy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = pd.merge_asof(dfTickets, dfBatteryLogsCopy, left_on = 'created_at', right_on = 'created_at' , by = 'batteryid_1', direction = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets['date_y']\n",
    "# del dfTickets['serialNo']\n",
    "# del dfTickets['changedBy']\n",
    "\n",
    "# dfTickets.rename({'occupant':'b1_occupant'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfBatteryLogsCopy.rename({'batteryid_1':'batteryid_2'}, axis = 1, inplace = True)\n",
    "# dfBatteryLogs.rename({'createdAt':'created_at'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets[dfTickets['battery_ids'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = dfTickets.sort_values(by = ['created_at', 'batteryid_2'])\n",
    "# dfBatteryLogsCopy = dfBatteryLogsCopy.sort_values(by = ['created_at', 'batteryid_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets = pd.merge_asof(dfTickets,dfBatteryLogsCopy, on = 'created_at', by = 'batteryid_2', direction = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfBatteryLogsCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets['date']\n",
    "# del dfTickets['serialNo']\n",
    "# del dfTickets['changedBy']\n",
    "\n",
    "# dfTickets.rename({'occupant':'b2_occupant', 'date_x': 'date'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query6 = '''\n",
    "select id partner_id, zoneId partnerZone, status partnerStatus from partners\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = prodFetch(query6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = dfTickets.merge(df6, on = 'partner_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets['date']\n",
    "# del dfTickets['serialNo']\n",
    "# del dfTickets['changedBy']\n",
    "\n",
    "# dfTickets.rename({'date_x':'date','occupant':'b2_occupant'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPenaltyWallet = adbFetch('''select date_add(date, interval 1 day) date, driverId complainant_id, round(penaltyWallet/100,0) penalty_wallet from dailyDriversHistories\n",
    "where date >= 20240930 and deletedAt is null and driverId like \"D%\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['date'] = pd.to_datetime(dfTickets['date']).dt.date\n",
    "dfTickets['hour'] = dfTickets['hour'].apply(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets = dfTickets.merge(dfPenaltyWallet, on = ['date', 'complainant_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfPenaltyWallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['penalty_wallet'] = dfTickets['penalty_wallet'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets['penalty_wallet'] = dfTickets['penalty_wallet'].apply(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverDetails = prodFetch('''\n",
    "select d.id complainant_id, d.clientid client_id, c.name client, (case when d.vehicleType in ('e-2w') then 'e-2w' else 'e-3w' end) vehicle_type,\n",
    "(case when clientId not in ('BS00') then true else false end) b2b_2w_flag, (case when clientId in ('BS00') and d.vehicleType not in ('E-2w') then true else false end) b2c_3w_flag, (case when clientId in ('BS00') and d.vehicleType in ('E-2w') then true else false end) b2c_2w_flag, d.isBaaSDriver baaS_flag, (case when datediff(date_add(current_date(),interval -1 day), d.liveDate) <= 30 then '<= 30 days' \n",
    "    \t  when (datediff(date_add(current_date(),interval -1 day), d.liveDate) between 31 and 90) then '31-90 days'\n",
    "    \t  when datediff(date_add(current_date(),interval -1 day), d.liveDate) > 90 and datediff(date_add(current_date(),interval -1 day), d.liveDate) <=365  then '91-365 days'\n",
    "          when datediff(date_add(current_date(),interval -1 day), d.liveDate) > 365 then '365+ days'\n",
    "     else 'NA'\n",
    "     end) age_cohort, dl.source driver_source, dl.sourceId source_id, u.mobile, u.alternatemobile alternate_mobile, d.operatorId operator_id, u2.mobile operator_mobile, d.status driver_status, d.liveDate driver_live_date,\n",
    "     (CASE WHEN d.status = 'active'\n",
    "   AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'to be activated'\n",
    "                WHEN d.status = 'active'\n",
    "                        AND d.isBatteryAvailable = 1\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'Active'\n",
    "                WHEN d.status = 'active'\n",
    "                        AND d.isBatteryAvailable = 1\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 1 THEN\n",
    "                        'Active Rental'\n",
    "                WHEN d.status = 'active'\n",
    "                        AND d.isBatteryAvailable = 1\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays > 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'Absent'\n",
    "                WHEN d.status = 'inactive'\n",
    "                        AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays >= 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'On Leave'\n",
    "                WHEN d.status = 'inactive'\n",
    "                        AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'To be onboarded'\n",
    "                WHEN d.status = 'inactive'\n",
    "                        AND d.isBatteryAvailable = 1\n",
    "                        AND d.isDefaulter = 1\n",
    "                        AND d.nonopsdays >= 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 1 THEN\n",
    "                        'Defaulter Rental'\n",
    "                WHEN d.status = 'inactive'\n",
    "                        AND d.isBatteryAvailable = 1\n",
    "                        AND d.isDefaulter = 1\n",
    "                        AND d.nonopsdays >= 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'Defaulter'\n",
    "                WHEN d.status = 'inactive'\n",
    "                        AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 1\n",
    "                        AND d.nonopsdays >= 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'Blocked'\n",
    "                WHEN d.status = 'left'\n",
    "                        AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'To be Deboarded'\n",
    "                WHEN d.status = 'left'\n",
    "                        AND d.isBatteryAvailable = 0\n",
    "                        AND d.isDefaulter = 0\n",
    "                        AND d.nonopsdays = 0\n",
    "                        AND d.livedate IS NOT NULL\n",
    "                        AND d.deletedat IS NOT NULL\n",
    "                        AND d.isBaaSDriver = 0 THEN\n",
    "                        'Deboarded'\n",
    "                ELSE\n",
    "                        '-'\n",
    "                END) driver_front_end_status\n",
    "from drivers d\n",
    "left join clients c on c.id = d.clientId\n",
    "left join driverLeads dl on dl.id = d.driverLeadId\n",
    "left join users u on u.employeeId = d.id\n",
    "left join driverOperators op on op.id = d.operatorId\n",
    "left join users u2 on u2.employeeId = d.operatorId\n",
    "where d.id like 'D%'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverDetails['mobile'] = dfDriverDetails['mobile'].apply(lambda x: '{:.0f}'.format(x))\n",
    "dfDriverDetails['alternate_mobile'] = dfDriverDetails['alternate_mobile'].apply(lambda x: '{:.0f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(dfDriverDetails, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfDriverDetails\n",
    "del dfDriverZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date'] = pd.to_datetime(dfTickets_copy['date'])\n",
    "\n",
    "dfTickets_copy.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.sort_values(by=['complainant_id', 'category_issue', 'created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_7D = dfTickets_copy[['complainant_id','category_issue','created_at']].groupby(['complainant_id', 'category_issue']).rolling('7D').count().reset_index().groupby(['complainant_id','category_issue','date']).agg(tickets=('created_at','max')).reset_index()\n",
    "\n",
    "grouped_df_7D = grouped_df_7D.reset_index(drop=True)\n",
    "\n",
    "grouped_df_7D.rename({'tickets':'L7Dtickets'}, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_7D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_14D = dfTickets_copy[['complainant_id','category_issue','created_at']].groupby(['complainant_id', 'category_issue']).rolling('14D').count().reset_index().groupby(['complainant_id','category_issue','date']).agg(tickets=('created_at','max')).reset_index()\n",
    "\n",
    "grouped_df_14D = grouped_df_14D.reset_index(drop=True)\n",
    "\n",
    "grouped_df_14D.rename({'tickets':'L14Dtickets'},axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_30D = dfTickets_copy[['complainant_id','category_issue','created_at']].groupby(['complainant_id','category_issue']).rolling('30D').count().reset_index().groupby(['complainant_id','category_issue','date']).agg(tickets=('created_at','max')).reset_index()\n",
    "\n",
    "grouped_df_30D = grouped_df_30D.reset_index(drop=True)\n",
    "\n",
    "grouped_df_30D.rename({'tickets':'L30Dtickets'},axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_60D = dfTickets_copy[['complainant_id','category_issue','created_at']].groupby(['complainant_id', 'category_issue']).rolling('60D').count().reset_index().groupby(['complainant_id','category_issue','date']).agg(tickets=('created_at','max')).reset_index()\n",
    "\n",
    "grouped_df_60D = grouped_df_60D.reset_index(drop=True)\n",
    "\n",
    "grouped_df_60D.rename({'tickets':'L60Dtickets'},axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_90D = dfTickets_copy[['complainant_id','category_issue','created_at']].groupby(['complainant_id', 'category_issue']).rolling('90D').count().reset_index().groupby(['complainant_id','category_issue','date']).agg(tickets=('created_at','max')).reset_index()\n",
    "\n",
    "grouped_df_90D = grouped_df_90D.reset_index(drop=True)\n",
    "\n",
    "grouped_df_90D.rename({'tickets':'L90Dtickets'},axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_90D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(grouped_df_7D, on = ['date','complainant_id','category_issue'], how='left')\n",
    "dfTickets_copy = dfTickets_copy.merge(grouped_df_14D, on = ['date','complainant_id','category_issue'], how='left')\n",
    "dfTickets_copy = dfTickets_copy.merge(grouped_df_30D, on = ['date','complainant_id','category_issue'], how='left')\n",
    "dfTickets_copy = dfTickets_copy.merge(grouped_df_60D, on = ['date','complainant_id','category_issue'], how='left')\n",
    "dfTickets_copy = dfTickets_copy.merge(grouped_df_90D, on = ['date','complainant_id','category_issue'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del grouped_df_7D\n",
    "del grouped_df_14D\n",
    "del grouped_df_30D\n",
    "del grouped_df_60D\n",
    "del grouped_df_90D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_copy[(df_copy['ticketTypeSubType']=='Charger Issue - Charger is not working')&(df_copy['complainantId']=='P2261')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ops Drivers & Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zonal daily Ops Drivers\n",
    "\n",
    "# query2 = '''\n",
    "# select t.date, d.zoneId complainant_zone, \n",
    "#     count(distinct(case when d.clientId not in ('BS00') then driverId end)) zone_day_B2B_2W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_day_B2C_3W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_day_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) zone_day_B2B_2W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_day_B2C_3W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_day_B2C_2W_txns\n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1,2\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = prodFetch(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['date'] = pd.to_datetime(df2['date'])\n",
    "# dfTickets_copy = dfTickets_copy.merge(df2, on = ['date','complainant_zone'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zonal weekly Ops Drivers\n",
    "\n",
    "# query3 = '''\n",
    "# select week(t.date,1) week_number, d.zoneId complainant_zone, \n",
    "#     count(distinct(case when d.clientId not in ('BS00') then driverId end)) zone_week_B2B_2W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_week_B2C_3W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_week_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) zone_week_B2B_2W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_week_B2C_3W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_week_B2C_2W_txns \n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1,2\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = prodFetch(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.merge(df3, on = ['week_number','complainant_zone'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns = prodFetch('''\n",
    "select date_format(date, '%Y-%m') month, date, date_add(createdAt, interval 330 minute) txn_created_at, driverId complainant_id, partnerId partner_id, batteriesIssued batteries_issued from transactions\n",
    "where date >= 20241001 and deletedAt is null\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {'[]':'', '[':'',']':'','\"':''}\n",
    "for old_char, new_char in replace_dict.items():\n",
    "    dfTxns['batteries_issued'] = dfTxns['batteries_issued'].str.replace(old_char, new_char)\n",
    "dfTxns[['B1_issued', 'B2_issued']] = dfTxns['batteries_issued'].str.split(',', expand = True)\n",
    "dfTxns['complainant_id'] = dfTxns['complainant_id'].astype(str)\n",
    "dfTickets_copy['complainant_id'] = dfTickets_copy['complainant_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverZone = prodFetch(\"\"\"select d.id complainant_id,\n",
    "d.zoneId complainant_zone, \n",
    "(case when clientId not in ('BS00') then true else false end) b2b_2w_flag,\n",
    "(case when clientId in ('BS00') and d.vehicleType not in ('E-2w') then true else false end) b2c_3w_flag,\n",
    "(case when clientId in ('BS00') and d.vehicleType in ('E-2w') then true else false end) b2c_2w_flag\n",
    "from drivers d\n",
    "where d.id like 'D%'\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDriverZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns = dfTxns.merge(dfDriverZone, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zm_b2c_3w = dfTxns[dfTxns['b2c_3w_flag'] == 1]\n",
    "df_zm_b2c_2w = dfTxns[dfTxns['b2c_2w_flag'] == 1]\n",
    "df_zm_b2b_2w = dfTxns[dfTxns['b2b_2w_flag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zm_b2c_3w = df_zm_b2c_3w.groupby(['month', 'complainant_zone']).agg( zone_monthly_B2C_3W_ops = ('complainant_id', 'nunique'), zone_monthly_B2C_3W_txns = ('complainant_id', 'count')).reset_index()\n",
    "df_zm_b2c_2w = df_zm_b2c_2w.groupby(['month', 'complainant_zone']).agg( zone_monthly_B2C_2W_ops = ('complainant_id', 'nunique'), zone_monthly_B2C_2W_txns = ('complainant_id', 'count')).reset_index()\n",
    "df_zm_b2b_2w = df_zm_b2b_2w.groupby(['month', 'complainant_zone']).agg( zone_monthly_B2B_2W_ops = ('complainant_id', 'nunique'), zone_monthly_B2B_2W_txns = ('complainant_id', 'count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zm_b2c_3w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(df_zm_b2c_3w, on = ['month','complainant_zone'], how = 'left')\n",
    "dfTickets_copy = dfTickets_copy.merge(df_zm_b2c_2w, on = ['month','complainant_zone'], how = 'left')\n",
    "dfTickets_copy = dfTickets_copy.merge(df_zm_b2b_2w, on = ['month','complainant_zone'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zm_b2c_3w = dfTxns[dfTxns['b2c_3w_flag'] == 1]\n",
    "df_zm_b2c_2w = dfTxns[dfTxns['b2c_2w_flag'] == 1]\n",
    "df_zm_b2b_2w = dfTxns[dfTxns['b2b_2w_flag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_b2c_3w = df_zm_b2c_3w.groupby(['month']).agg( monthly_B2C_3W_ops = ('complainant_id', 'nunique'), monthly_B2C_3W_txns = ('complainant_id', 'count')).reset_index()\n",
    "df_m_b2c_2w = df_zm_b2c_2w.groupby(['month']).agg( monthly_B2C_2W_ops = ('complainant_id', 'nunique'), monthly_B2C_2W_txns = ('complainant_id', 'count')).reset_index()\n",
    "df_m_b2b_2w = df_zm_b2b_2w.groupby(['month']).agg( monthly_B2B_2W_ops = ('complainant_id', 'nunique'), monthly_B2B_2W_txns = ('complainant_id', 'count')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zm_b2c_2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_zm_b2c_3w\n",
    "del df_zm_b2c_2w\n",
    "del df_zm_b2b_2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(df_m_b2c_3w, on = 'month', how = 'left')\n",
    "dfTickets_copy = dfTickets_copy.merge(df_m_b2c_2w, on = 'month', how = 'left')\n",
    "dfTickets_copy = dfTickets_copy.merge(df_m_b2b_2w, on = 'month', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.ticketId == 'D240204-8283-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPrel = dfTickets_copy[dfTickets_copy['assigned_to_team']==\"P-Rel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfPrel[dfPrel['ticket_id']=='D240808-129143']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write(\"https://docs.google.com/spreadsheets/d/1pFystBfFB2YzuBwfOXAv_UpXX8dyt76XD66SPemIuSc/edit?gid=1988316138#gid=1988316138\", \"Raw_Data\", dfPrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # daily ops drivers\n",
    "\n",
    "# query7 = '''\n",
    "# select t.date, \n",
    "#     count(distinct(case when d.clientId not in ('BS00') then driverId end)) day_B2B_2W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) day_B2C_3W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) day_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) day_B2B_2W_txn, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) day_B2C_3W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) day_B2C_2W_txns\n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df7 = prodFetch(query7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df7['date'] = pd.to_datetime(df7['date'])\n",
    "# dfTickets_copy = dfTickets_copy.merge(df7, on = 'date', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weekly Ops Drivers\n",
    "\n",
    "# query8 = '''\n",
    "# select week(t.date,1) week_number, \n",
    "#     count(distinct(case when d.clientId not in ('BS00') then driverId end)) week_B2B_2W_ops,\n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) week_B2C_3W_ops, \n",
    "#     count(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) week_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) week_B2B_2W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) week_B2C_3W_txns, \n",
    "#     count((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) week_B2C_2W_txns\n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df8 = prodFetch(query8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.merge(df8, on = 'week_number', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df11['date'] = pd.to_datetime(df11['date'])\n",
    "# df11['hour'] = df11['hour'].apply(np.float64)\n",
    "# dfTickets_copy = dfTickets_copy.merge(df11, on = ['date','hour'],  how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zonal Weekly (Hourwise) Ops Drivers\n",
    "\n",
    "# query12 = '''\n",
    "# select week(t.date,1) week_number, hour(date_add(t.createdAt, interval 330 minute)) hour,\n",
    "# \td.zoneId complainant_zone,\n",
    "# \tcount(distinct(case when d.clientId not in ('BS00') then driverId end)) zone_hr_week_B2B_2W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_hr_week_B2C_3W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_hr_week_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) zone_hr_week_B2B_2W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_hr_week_B2C_3W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_hr_week_B2C_2W_txns\n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date < current_date() and t.deletedAt is null\n",
    "# group by 1,2,3\n",
    "# '''\n",
    "\n",
    "# # Weekly (Hourwise) Ops Drivers\n",
    "\n",
    "# query13 = '''\n",
    "# select week(t.date,1) week_number,\n",
    "# \thour(date_add(t.createdAt, interval 330 minute)) hour,\n",
    "# \tcount(distinct(case when d.clientId not in ('BS00') then driverId end)) hr_week_B2B_2W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) hr_week_B2C_3W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) hr_week_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) hr_week_B2B_2W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) hr_week_B2C_3W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) hr_week_B2C_2W_txns \n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1,2\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df12 = prodFetch(query12)\n",
    "# df13 = prodFetch(query13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df12['hour'] = df12['hour'].apply(np.float64)\n",
    "# dfTickets_copy = dfTickets_copy.merge(df12, on = ['week_number','hour', 'complainant_zone'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df13['hour'] = df13['hour'].apply(np.float64)\n",
    "# dfTickets_copy = dfTickets_copy.merge(df13, on = ['week_number','hour'] ,how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zonal Monthly (Hourwise) Ops Drivers \n",
    "\n",
    "# query14 = '''\n",
    "# select date_format(t.date, '%Y-%m') month, hour(date_add(t.createdAt, interval 330 minute)) hour,\n",
    "# \td.zoneId complainant_zone,\n",
    "# \tcount(distinct(case when d.clientId not in ('BS00') then driverId end)) zone_hr_monthly_B2B_2W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_hr_monthly_B2C_3W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_hr_monthly_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) zone_hr_monthly_B2B_2W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) zone_hr_monthly_B2C_3W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) zone_hr_monthly_B2C_2W_txns \n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1,2,3\n",
    "# '''\n",
    "\n",
    "# # Monthly (Hourwise) Ops Drivers\n",
    "\n",
    "# query15 = '''\n",
    "# select date_format(t.date, '%Y-%m') month, hour(date_add(t.createdAt, interval 330 minute)) hour,\n",
    "# \tcount(distinct(case when d.clientId not in ('BS00') then driverId end)) hr_monthly_B2B_2W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) hr_monthly_B2C_3W_ops, \n",
    "# \tcount(distinct(case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) hr_monthly_B2C_2W_ops,\n",
    "#     count((case when d.clientId not in ('BS00') then driverId end)) hr_monthly_B2B_2W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType not in ('E-2w') then driverId end)) hr_monthly_B2C_3W_txns, \n",
    "# \tcount((case when d.clientId in ('BS00') and d.vehicleType in ('E-2w') then driverId end)) hr_monthly_B2C_2W_txns \n",
    "# from transactions t\n",
    "# left join drivers d on d.id = t.driverId\n",
    "# where t.date >= 20240701 and t.date <= current_date() and t.deletedAt is null\n",
    "# group by 1,2\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df14 = prodFetch(query14)\n",
    "# df15 = prodFetch(query15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df14['hour'] = df14['hour'].apply(np.float64)\n",
    "# dfTickets_copy = dfTickets_copy.merge(df14, on = ['month','hour', 'complainant_zone'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df15['hour'] = df15['hour'].apply(np.float64)\n",
    "# dfTickets_copy = dfTickets_copy.merge(df15, on = ['month','hour'] , how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxnsGr = prodFetch(\"\"\"select driverId complainant_id, count(DISTINCT(date)) txn_days from transactions\n",
    "where (date >= date_add(current_date(), interval -90 day) and date < current_date()) and deletedAt is null -- and clientId in ('BS00')\n",
    "group by 1\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays = prodFetch(\"\"\"select driverId complainant_id, count(case when status in ('active') then driverId end) active_days, count(date) total_days from driverStatusHistories\n",
    "where (date >= date_add(current_date(), interval -90 day) and date < current_date()) and deletedAt is null and driverId like 'D%'\n",
    "group by 1\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays = dfActiveDays.merge(dfTxnsGr, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays = dfActiveDays.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays['active_days'] = np.where(dfActiveDays['active_days'] < dfActiveDays['txn_days'], dfActiveDays['txn_days'],  dfActiveDays['active_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays['txn_days/active_days'] =  (dfActiveDays['txn_days']/dfActiveDays['active_days']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define txn/active days cohort\n",
    "\n",
    "conditions = [\n",
    "    ((dfActiveDays['txn_days/active_days'] >= 0) & (dfActiveDays['txn_days/active_days'] <=0.10)),\n",
    "    ((dfActiveDays['txn_days/active_days'] > 0.10) & (dfActiveDays['txn_days/active_days'] <=0.25)),\n",
    "    ((dfActiveDays['txn_days/active_days'] > 0.25) & (dfActiveDays['txn_days/active_days'] <=0.5)),\n",
    "    ((dfActiveDays['txn_days/active_days'] > 0.5) & (dfActiveDays['txn_days/active_days'] <=0.75)),\n",
    "    ((dfActiveDays['txn_days/active_days'] > 0.75) & (dfActiveDays['txn_days/active_days'] <=0.9)),\n",
    "    ((dfActiveDays['txn_days/active_days'] > 0.9))\n",
    "]\n",
    "\n",
    "# Define the corresponding output for each condition\n",
    "choices = ['A(0% - 10%)', 'B(11% - 25%)', 'C(26% - 50%)', 'D(51% - 75%)', 'E(76% - 90%)', 'F(91% - 100%)' ]\n",
    "\n",
    "# Apply the conditions to create the 'age_cohort' column\n",
    "dfActiveDays['txn_active_cohort'] = np.select(conditions, choices, default='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfActiveDays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(dfActiveDays, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqCols = ['date', 'txn_created_at', 'complainant_id', 'partner_id','B1_issued', 'B2_issued' ]\n",
    "dfTxns = dfTxns[reqCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns['complainant_id'] = dfTxns['complainant_id'].astype(str)\n",
    "dfTickets_copy['complainant_id'] = dfTickets_copy['complainant_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns = dfTxns.sort_values(by = ['txn_created_at', 'complainant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.sort_values(by = ['created_at', 'complainant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = pd.merge_asof(dfTickets_copy, dfTxns, left_on = 'created_at', right_on = 'txn_created_at', by = 'complainant_id', direction = 'backward', suffixes=('', '_prev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.sort_values(by = ['created_at', 'complainant_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure the indexes are reset after sorting\n",
    "# dfTxns.reset_index(drop=True, inplace=True)\n",
    "# dfTickets_copy.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = pd.merge_asof(dfTickets_copy,dfTxns, left_on = 'created_at', right_on = 'txn_created_at', by = 'complainant_id', direction = 'forward', suffixes=('', '_next'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMultipleTickets = dfTickets_copy.groupby(['date', 'complainant_id', 'category_issue']).agg({'ticket_id':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMultipleTickets.rename({'ticket_id':'same_day_ticket_count'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.merge(dfMultipleTickets, on = ['date', 'complainant_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy['L7D_tickets'] = 0\n",
    "# dfTickets_copy['L14D_tickets'] = 0\n",
    "# dfTickets_copy['L30D_tickets'] = 0\n",
    "# dfTickets_copy['L60D_tickets'] = 0\n",
    "# dfTickets_copy['L90D_tickets'] = 0\n",
    "# dfTickets_copy['C0_choking'] = 0\n",
    "# dfTickets_copy['C1_choking'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfChokingScore = adbFetch('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy['remark'] = dfTickets_copy['remark'].astype(str) \n",
    "# dfTickets_copy['rejectionremarks'] = dfTickets_copy['rejectionremarks'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['remark'] = dfTickets_copy['remark'].str.replace('+', ' ')\n",
    "# dfTickets_copy['remark'] = dfTickets_copy['remark'].str.replace(' ', '')\n",
    "dfTickets_copy['remark'] = dfTickets_copy['remark'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['remark'] = dfTickets_copy['remark'].str.replace('+', ' ')\n",
    "# dfTickets_copy['remark'] = dfTickets_copy['remark'].str.replace(' ', '')\n",
    "dfTickets_copy['remark'] = dfTickets_copy['remark'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['rejectionremarks'] = dfTickets_copy['rejectionremarks'].str.replace('+', ' ')\n",
    "# dfTickets_copy['rejectionremarks'] = dfTickets_copy['rejectionremarks'].str.replace(' ', '')\n",
    "dfTickets_copy['rejectionremarks'] = dfTickets_copy['rejectionremarks'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy.iloc[1:20].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date'] = pd.to_datetime(dfTickets_copy['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date_next'] = pd.to_datetime(dfTickets_copy['date_next'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy['date_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets_copy['category_issue_y']\n",
    "# del dfTickets_copy['batteries_issued']\n",
    "# del dfTickets_copy['batteries_issued_next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renameCols = {'category_issue_x':'category_issue', 'txn_created_at':'txn_created_at_prev','B1_issued':'B1_issued_prev', 'B2_issued':'B2_issued_prev'}\n",
    "\n",
    "dfTickets_copy.rename(renameCols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['now'] = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pandas as pd, numpy as np, json, pygsheets as pg\n",
    "sys.path.append('../connectors')\n",
    "sys.path.append('../utils')\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from queryHelper import *\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import h3\n",
    "\n",
    "locationsDf = prodMongoFetch(collection= 'driverAggregateLocations', pipeline= []).drop(columns = ['_id'])\n",
    "locationsDf['mpl'] = locationsDf['locations'].apply(lambda x : x[0])\n",
    "\n",
    "locationsDf['lat'] = locationsDf['mpl'].apply(lambda x : x.get('lat'))\n",
    "locationsDf['lon'] = locationsDf['mpl'].apply(lambda x : x.get('lon'))\n",
    "locationsDf['instances'] = locationsDf['mpl'].apply(lambda x : x.get('instances'))\n",
    "locationsDf['probability'] = locationsDf['mpl'].apply(lambda x : x.get('probability'))\n",
    "\n",
    "del(locationsDf['locations'])\n",
    "del(locationsDf['mpl'])\n",
    "\n",
    "locationsDf = locationsDf[(locationsDf.probability > 0.5) | (locationsDf.instances > 15)].sort_values(by = 'driverId').reset_index(drop = True)\n",
    "\n",
    "locationsDf['driverH3Id'] = locationsDf.apply(lambda row : h3.geo_to_h3(row['lat'], row['lon'], 7), axis = 1)\n",
    "\n",
    "locationsDf.rename({'driverId':'complainant_id'}, axis = 1, inplace = True)\n",
    "\n",
    "# del locationsDf['lat']\n",
    "# del locationsDf['lon']\n",
    "# del locationsDf['instances']\n",
    "# del locationsDf['probability']\n",
    "\n",
    "locationsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.merge(locationsDf, on = 'complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy = dfTickets_copy.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del locationsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy.rename({'assinged_to_team':'assigned_to_role_team'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"ankit_das\", password = \"Ankit@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "# print('PostgreSQL Connection Established')\n",
    "\n",
    "# # Fetch Data from PostgreSQL server\n",
    "\n",
    "# query1 = '''with v1 as \n",
    "# (\n",
    "# select\n",
    "#     TO_CHAR((t.created_at + INTERVAL '330 minute')::date, 'YYYY-MM') as month,\n",
    "#     EXTRACT(WEEK FROM (t.created_at + INTERVAL '330 minute')::date) AS week_number,\n",
    "#     (case \n",
    "#     \twhen (EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 1 and EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) <= 10) then '1-10' \n",
    "#     \twhen (EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 11 and EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) <= 20) then '11-20'\n",
    "#     \twhen EXTRACT(DAY FROM (t.created_at + INTERVAL '330 minute')::date) >= 21 then '21+' \n",
    "#     end) day_cohort,\n",
    "#     to_char((t.created_at + INTERVAL '330 minute')::date, 'Day') as day,\n",
    "#     (t.created_at + INTERVAL '330 minute')::date AS date,\n",
    "#     t.created_at + INTERVAL '330 minute' AS created_at,\n",
    "#     t.updated_at + INTERVAL '330 minute' AS updated_at,\n",
    "#     TO_CHAR(t.created_at + INTERVAL '330 minutes', 'HH24') as hour,\n",
    "#     t.slug ticket_id,\n",
    "#     tasks.status ticket_status,\n",
    "#     (case when t.complainant_type = 1 then 'driver' else 'partner' end) complainant_type,\n",
    "#     t.complainant_id complainant_id,\n",
    "#     ic.id category_id,\n",
    "#     ic.name category_name,\n",
    "#     t.issue_id issue_id,\n",
    "#     i1.name issue_name,\n",
    "#     concat(ic.name,' - ',i1.name) category_issue,\n",
    "#     t.complainant_name complainant_name,\n",
    "#     t.zone complainant_zone,\n",
    "#     t.source,\n",
    "#     COALESCE(t.calling_number, '') calling_number,\n",
    "#     round(EXTRACT(EPOCH FROM (t.sla - t.created_at))/3600,0) sla_in_hrs,\n",
    "#     y.done_by created_by,\n",
    "#     (case when iar.assignment_rule_type like '%TeamRole%' then 'Team Role' else 'RM' end) assingment_role,\n",
    "#     tarm.team rmTeam,\n",
    "#     COALESCE((case when iar.assignment_rule_type like '%TeamRole%' then tatr.team else NULL end),' ') assigned_to_team,\n",
    "#     COALESCE((case when iar.assignment_rule_type like '%TeamRole%' then tatr.role else NULL end ), '') assigned_to_role,\n",
    "#     tasks.id taskId,\n",
    "#     COALESCE(tasks.location, '') taskLocation,\n",
    "#     COALESCE(x.rejectionCount,0) taskRejectionCount,\n",
    "#     COALESCE(x.rejectionReasons,'') rejectionReasons,\n",
    "#     COALESCE(x.rejectionRemarks,'') rejectionRemarks,\n",
    "#     battery_ids,\n",
    "#     split_part(battery_ids, ',', 1) AS batteryid_1,\n",
    "#     split_part(battery_ids, ',', 2) AS batteryid_2,\n",
    "#     charger_ids,\n",
    "#     partner_id, \n",
    "#     driver_id\n",
    "# from tickets t\n",
    "# left join issues i1 on t.issue_id = i1.id\n",
    "# left join issue_categories ic on ic.id = i1.issue_category_id\n",
    "# left join tasks on tasks.id = t.task_id\n",
    "# left join issue_assignment_rules iar on iar.issue_id = t.issue_id\n",
    "# left join tickets_assignment_rules_relationship_managers tarm on tarm.id = iar.assignment_rule_id\n",
    "# left join tickets_assignment_rules_team_roles tatr on tatr.id = iar.assignment_rule_id\n",
    "# left join (\n",
    "# with v1 as \n",
    "# (\n",
    "# select loggable_type, loggable_id, to_value, count(id) rejectionCount, string_agg(reason, E' >> ') rejectionReasons, string_agg(remark, E' >> ') rejectionRemarks from logs\n",
    "# where to_value = 'rejected'\n",
    "# group by 1,2,3\n",
    "# )\n",
    "# select * from v1) x on x.loggable_id = t.task_id\n",
    "# left join (\n",
    "# with logData as \n",
    "# (\n",
    "# select loggable_type, loggable_id, from_value, to_value, reason, remark, done_by, event_name, ROW_NUMBER() over(partition by loggable_id order by created_at) rank from logs \n",
    "# )\n",
    "# select * from logData \n",
    "# where rank = 1 and loggable_type in ('Task')\n",
    "# ) y on y.loggable_id = t.task_id\n",
    "# where t.deleted_at is null\n",
    "# )\n",
    "# select * from v1\n",
    "# '''\n",
    "\n",
    "# dfTickets2 = pd.read_sql(query1, conn)\n",
    "\n",
    "\n",
    "# # dfTickets\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect(dbname = \"operations_manager_prod\", user = \"ankit_das\", password = \"Ankit@12345\", host = \"operation.replica.upgrid.in\", port = \"5432\")\n",
    "\n",
    "# print('PostgreSQL Connection Established')\n",
    "\n",
    "# query3 = '''\n",
    "# select l.loggable_type, l.loggable_id, l.attr, l.from_value, l.to_value, l.reason, l.remark, l.event_name, l.done_by,  l.created_at + INTERVAL '330 minute' created_at, l.updated_at + INTERVAL '330 minute' updated_at,\n",
    "# COALESCE(t.parent_id,l.loggable_id) parent_Id\n",
    "# from logs l\n",
    "# left join tasks t on l.loggable_id = t.id \n",
    "# where deleted_at is null  and (t.created_at + INTERVAL '330 minute')::date >= '20240801' and l.remark not like 'Assigned to%' and l.remark != ''\n",
    "# '''\n",
    "\n",
    "# dfTat = pd.read_sql(query3, conn)\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTat['created_at'] = pd.to_datetime(dfTat['created_at'])\n",
    "# dfTat['updated_at'] = pd.to_datetime(dfTat['updated_at'])\n",
    "# dfTat.rename({'parent_id':'taskid'}, axis = 1, inplace = True)\n",
    "\n",
    "# dfUsers = prodFetch(\"\"\"select employeeId temp, (case when teams in ('[]') then role else teams end) team, roleV2 from users \n",
    "# where employeeId not like 'D%' or employeeId not like 'P%'\"\"\")\n",
    "\n",
    "# replace_dict = {'[]':'', '[':'',']':'','\"':''}\n",
    "\n",
    "# dfUsers['roleV2'] = dfUsers['roleV2'].fillna('')\n",
    "\n",
    "# dfUsers['assinged_to_team'] = dfUsers['team'] + \" - \" + dfUsers['roleV2']\n",
    "\n",
    "# del dfUsers['team']\n",
    "# del dfUsers['roleV2']\n",
    "\n",
    "# dfTat['temp'] = dfTat['done_by'].str[:8].str.replace(' ', '')\n",
    "\n",
    "# dfTat = dfTat.merge(dfUsers, on = 'temp', how = 'left')\n",
    "\n",
    "# dfTat.rename({'temp':'done_by_id'}, axis = 1, inplace = True)\n",
    "\n",
    "# dfOSC = ['operationsSupportTeam - centralAssociate','operationsSupportTeam - centralAssociate','[\"centralOsc\"] - fieldExecutive','[\"centralOsc\"] - centralAssociate','operationsSupportTeam - centralTeamLead','[\"centralOsc\"] - admin',\n",
    "# ]\n",
    "\n",
    "# dfOscRemarks = dfTat[dfTat['assinged_to_team'].isin(dfOSC)]\n",
    "\n",
    "# dfOscRemarks = dfOscRemarks.merge(dfTickets2, on = 'taskid', how = 'left')\n",
    "\n",
    "# dfRemarks = dfOscRemarks.groupby(['ticket_id']).agg({'remark':'count'}).reset_index()\n",
    "\n",
    "# dfRemarks.rename({'remark':'osc_remarks'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfRemarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.merge(dfRemarks, on = 'ticket_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy['osc_remarks'] = dfTickets_copy['osc_remarks'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Get If The Vehicle is Registered or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfVehicleReg = prodFetch(\"\"\"with v1 as \n",
    "# (\n",
    "# select driverId, registrationNumber, registrationDate, date(fitnessCertificateExpiryDate) fitnessCertificateExpiryDate from driverVehicleVerificationLogs\n",
    "# union\n",
    "# select driverId, registrationNo, date(registrationDate) registrationDate, NULL fitnessCertificateExpiryDate  from driverOnboardingDatas\n",
    "# where driverId is not null\n",
    "# ),\n",
    "# prefinal as \n",
    "# (\n",
    "# select driverId, GROUP_concat(registrationNumber) registrationNumber, date(max(registrationDate)) registrationDate, date(max(fitnessCertificateExpiryDate)) fitnessCertificateExpiryDate from v1\n",
    "# group by 1\n",
    "# ),\n",
    "# prefinal2 as \n",
    "# (\n",
    "# select driverId,\n",
    "# \t   registrationNumber,\n",
    "# \t   (case when registrationDate < 20100101 then NULL else registrationDate end) registrationDate\n",
    "# from prefinal\n",
    "# )\n",
    "# select a.*,  date_add(registrationDate, interval 2 year) fitnessCertificateExpiryDate, (case when registrationDate is not null then 1 else 0 end) registrationFlag, (case when date_add(registrationDate, interval 2 year) > current_date() then 1 else 0 end) vehicleFitnessFlag\n",
    "# from prefinal2 a\n",
    "# left join drivers d on a.driverId = d.id\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfVehicleReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy = dfTickets_copy.merge(dfVehicleReg, left_on = 'complainant_id', right_on = 'driverId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy['registrationFlag'] = dfTickets_copy['registrationFlag'].fillna(\"\") \n",
    "# dfTickets_copy['vehicleFitnessAvailable'] = dfTickets_copy['vehicleFitnessAvailable'].fillna(\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfTickets_copy['driverId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTickets_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver Age Cohort Basis Ticket Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfTickets_copy['age_cohort']\n",
    "\n",
    "dfTickets_copy['date'] = pd.to_datetime(dfTickets_copy['date'])\n",
    "dfTickets_copy['driver_live_date'] = pd.to_datetime(dfTickets_copy['driver_live_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date_diff'] = (dfTickets_copy['date'] - dfTickets_copy['driver_live_date']).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date_diff'] = dfTickets_copy['date_diff'].fillna(0)\n",
    "\n",
    "# dfTickets_copy['date_diff'] = np.where(dfTickets_copy['date_diff'] == \"\", 0, dfTickets_copy['date_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions for the age cohort\n",
    "conditions = [\n",
    "    (dfTickets_copy['date_diff'] <= 30),\n",
    "    (dfTickets_copy['date_diff'] >= 31) & (dfTickets_copy['date_diff'] <= 90),\n",
    "    (dfTickets_copy['date_diff'] > 90) & (dfTickets_copy['date_diff'] <= 365),\n",
    "    (dfTickets_copy['date_diff'] > 365)\n",
    "]\n",
    "\n",
    "# Define the corresponding output for each condition\n",
    "choices = ['<= 30 days', '31-90 days', '91-365 days', '365+ days']\n",
    "\n",
    "# Apply the conditions to create the 'age_cohort' column\n",
    "dfTickets_copy['age_cohort'] = np.select(conditions, choices, default='')\n",
    "\n",
    "# Drop the date_diff column if you no longer need it\n",
    "dfTickets_copy.drop(columns=['date_diff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['age_cohort'] = np.where(dfTickets_copy['complainant_type']=='partner', \"\", dfTickets_copy['age_cohort']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTicketsVehicle = dfTickets[dfTickets['category_name']=='Vehicle Issue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTicketsVehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (dfTickets_copy.groupby('ticket_id').agg({'category_issue':'count'}).reset_index()).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTicketsVehicle.groupby(['month','complainant_zone']).agg({'ticket_id':'count', 'osc_remarks':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCallingNumber = prodFetch(\"\"\"with v1 as \n",
    "(\n",
    "select customerId, callingNumber, count, row_number() over(partition by customerId order by count desc) rank  from customerCallingNumbers\n",
    "where deletedAt is null\n",
    "-- group by 1,2\n",
    ")\n",
    "select customerId complainant_id, callingNumber primary_number from v1\n",
    "where rank = 1\"\"\")\n",
    "\n",
    "dfTickets_copy = dfTickets_copy.merge(dfCallingNumber, on ='complainant_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dfCallingNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy['date'] = dfTickets_copy['date'].dt.date\n",
    "dfTickets_copy['driver_live_date'] = pd.to_datetime(dfTickets_copy['driver_live_date']).dt.date\n",
    "dfTickets_copy['date_next'] = pd.to_datetime(dfTickets_copy['date_next']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTickets_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote\n",
    "\n",
    "user = os.getenv('SQL_USER2')\n",
    "password = quote(os.getenv('SQL_PWD2'), safe ='')\n",
    "url = os.getenv('SQL_HOST2')\n",
    "databaseUrl = f\"mysql+pymysql://{user}:{password}@{url}/analytics_prod?charset=utf8mb4\"\n",
    "\n",
    "engine = create_engine(databaseUrl)\n",
    "dfTickets_copy.to_sql('ticketModelNew', con = engine, if_exists = 'replace', index = False, dtype = {'remark': sqlalchemy.types.TEXT(collation='utf8mb4_unicode_ci'), \n",
    "'rejectionremarks': sqlalchemy.types.TEXT(collation='utf8mb4_unicode_ci'), 'tasklocation': sqlalchemy.types.TEXT(collation='utf8mb4_unicode_ci')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Write B2B TMS data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sheetHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB2B = adbFetch('''\n",
    "\n",
    "select distinct(ticket_id), date, month, week_number, day, created_at, updated_at, ticket_status, \n",
    "complainant_type, complainant_id, category_name, issue_name, category_name, complainant_name, source, calling_number, taskrejectioncount,partner_id, complainant_zone, resolution, remark, \n",
    "client_id, client,left(complainant_zone,3) as region,\n",
    "case when LEFT(complainant_zone, 3) in ('NWD','NMV','SHG','FSD','DNG') then 'NCR' else LEFT(complainant_zone, 3) end as region2\n",
    "\n",
    "from ticketModelNew\n",
    "where b2b_2w_flag = 1\n",
    "order by date desc\n",
    "'''\n",
    ")\n",
    "\n",
    "write('https://docs.google.com/spreadsheets/d/1W_pl-LND1ED1xqpfLPGDrphGak-8bRWAfCbhwgS3fMI/edit?gid=505628546#gid=505628546', \"TMS Raw\", dfB2B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
